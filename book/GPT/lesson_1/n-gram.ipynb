{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. 构建语料库"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d02bd2689094b2ce"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"我喜欢吃苹果\",\n",
    "    \"我喜欢吃香蕉\",\n",
    "    \"她喜欢吃葡萄\",\n",
    "    \"他不喜欢吃香蕉\",\n",
    "    \"他喜欢吃苹果\",\n",
    "    \"她喜欢吃草莓\"\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:29:27.975796Z",
     "start_time": "2024-03-14T06:29:27.952873Z"
    }
   },
   "id": "90fb78df6fa0f6cb",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. 把句子分成 n 个 Gram"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56ede375d0f49a5b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return [char for char in text]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:29:27.980285Z",
     "start_time": "2024-03-14T06:29:27.977462Z"
    }
   },
   "id": "9c6baad6eaea4026",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. 计算每个 Bigram 在语料库中的词频"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d6ec8d717ee99a1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "def count_ngrams(corpus, n):\n",
    "    ngrams_count = defaultdict(Counter)\n",
    "    for text in corpus:\n",
    "        tokens = tokenize(text)\n",
    "        for i in range(len(tokens) - n + 1):\n",
    "            ngram = tuple(tokens[i:i+n])\n",
    "            prefix = ngram[:-1]\n",
    "            token = ngram[-1]\n",
    "            ngrams_count[prefix][token] += 1\n",
    "    return ngrams_count\n",
    "\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:29:27.985326Z",
     "start_time": "2024-03-14T06:29:27.981443Z"
    }
   },
   "id": "3ed994b6ef0d4d62",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram 词频:\n",
      "我:{'喜': 2}\n",
      "喜:{'欢': 6}\n",
      "欢:{'吃': 6}\n",
      "吃:{'苹': 2, '香': 2, '葡': 1, '草': 1}\n",
      "苹:{'果': 2}\n",
      "香:{'蕉': 2}\n",
      "她:{'喜': 2}\n",
      "葡:{'萄': 1}\n",
      "他:{'不': 1, '喜': 1}\n",
      "不:{'喜': 1}\n",
      "草:{'莓': 1}\n"
     ]
    }
   ],
   "source": [
    "bigram_counts = count_ngrams(corpus, 2)\n",
    "print(\"Bigram 词频:\")\n",
    "for prefix, counts in bigram_counts.items():\n",
    "    print(f\"{''.join(prefix)}:{dict(counts)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:29:27.990981Z",
     "start_time": "2024-03-14T06:29:27.987561Z"
    }
   },
   "id": "c1def355fa497bcc",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. 计算每个 Bigram 出现的概率"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f4c8bec85f2074a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def ngram_probability(ngram_counts):\n",
    "    ngram_probs = defaultdict(Counter)\n",
    "    for prefix, tokens_count in ngram_counts.items():\n",
    "        total_counts = sum(tokens_count.values())\n",
    "        for token, count in tokens_count.items():\n",
    "            ngram_probs[prefix][token]  = count/total_counts\n",
    "    return ngram_probs\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:29:27.994320Z",
     "start_time": "2024-03-14T06:29:27.991862Z"
    }
   },
   "id": "47c5401d3a84140d",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram 出现的概率\n",
      "我:{'喜': 1.0}\n",
      "喜:{'欢': 1.0}\n",
      "欢:{'吃': 1.0}\n",
      "吃:{'苹': 0.3333333333333333, '香': 0.3333333333333333, '葡': 0.16666666666666666, '草': 0.16666666666666666}\n",
      "苹:{'果': 1.0}\n",
      "香:{'蕉': 1.0}\n",
      "她:{'喜': 1.0}\n",
      "葡:{'萄': 1.0}\n",
      "他:{'不': 0.5, '喜': 0.5}\n",
      "不:{'喜': 1.0}\n",
      "草:{'莓': 1.0}\n"
     ]
    }
   ],
   "source": [
    "bigram_probs = ngram_probability(bigram_counts)\n",
    "print(\"Bigram 出现的概率\")\n",
    "for prefix, probs in bigram_probs.items():\n",
    "    print(f\"{''.join(prefix)}:{dict(probs)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:29:27.998434Z",
     "start_time": "2024-03-14T06:29:27.995615Z"
    }
   },
   "id": "11e2ec26b96fe34c",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. 根据 Bigram 出现的概率, 定义生成下一个词的函数"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4423b864afdf32ce"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generate_next_tokens(prefix, ngram_probs):\n",
    "    if prefix not in ngram_probs:\n",
    "        return None\n",
    "    next_token_probs = ngram_probs[prefix]\n",
    "    next_token = max(next_token_probs, key=next_token_probs.get)\n",
    "    return next_token"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:29:28.002518Z",
     "start_time": "2024-03-14T06:29:27.999657Z"
    }
   },
   "id": "3b81c8be9950513d",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "喜\n"
     ]
    }
   ],
   "source": [
    "print(generate_next_tokens(tuple(\"不\",), bigram_probs))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:29:28.006578Z",
     "start_time": "2024-03-14T06:29:28.004428Z"
    }
   },
   "id": "c92285103f0708d5",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. 输入前缀, 生成连续文本"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d6067d5a44069db"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generate_text(prefix, ngram_probs, n, length=6):\n",
    "    tokens = list(prefix)\n",
    "    for _ in range(length - len(prefix)):\n",
    "        next_token = generate_next_tokens(tuple(tokens[-(n-1):]), ngram_probs)\n",
    "        if not next_token:\n",
    "            break\n",
    "        tokens.append(next_token)\n",
    "    return \"\".join(tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:29:28.009930Z",
     "start_time": "2024-03-14T06:29:28.007603Z"
    }
   },
   "id": "e4b4eae917a8e477",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我喜欢吃苹果\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\"我\", bigram_probs, 2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:29:28.012898Z",
     "start_time": "2024-03-14T06:29:28.010817Z"
    }
   },
   "id": "c787cd13c8c110a5",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:29:28.016597Z",
     "start_time": "2024-03-14T06:29:28.015116Z"
    }
   },
   "id": "72269c5c8eedbafc",
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
