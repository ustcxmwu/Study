{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. 简单自注意力"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f488708437cb4a43"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2774,  1.3247, -0.6158, -1.9739],\n",
      "         [-0.9119,  1.0185, -0.8377,  0.3188],\n",
      "         [-1.0841,  0.8404, -1.2366,  0.8150]],\n",
      "\n",
      "        [[-0.1870,  0.0952,  1.3785,  0.0742],\n",
      "         [-0.3248, -0.1043,  0.0555, -0.7568],\n",
      "         [-0.3077, -0.1424,  0.2153, -0.6645]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "x = torch.randn(2, 3, 4)\n",
    "raw_weights = torch.bmm(x, x.transpose(1, 2))\n",
    "attn_weights = F.softmax(raw_weights, dim=2)\n",
    "attn_outputs = torch.bmm(attn_weights, x)\n",
    "print(attn_outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T09:27:59.713785Z",
     "start_time": "2024-03-26T09:27:59.701800Z"
    }
   },
   "id": "db5976e82194dfb5",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. 标准自注意力"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a7de25afa54ff36"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 4.4115e-02, -4.3930e-01, -6.8740e-01],\n",
      "         [-3.9619e-01,  3.0652e-01, -1.3978e+00],\n",
      "         [ 1.4006e-01, -5.7866e-01, -3.7079e-01]],\n",
      "\n",
      "        [[ 1.1333e-02, -5.1178e-01, -4.0106e-01],\n",
      "         [ 1.9789e-03, -7.4621e-01, -2.6430e+00],\n",
      "         [-3.7205e-02,  4.7986e-01, -8.4291e-01]]], grad_fn=<BmmBackward0>)\n",
      "tensor([[[ 2.2057e-02, -2.1965e-01, -3.4370e-01],\n",
      "         [-1.9809e-01,  1.5326e-01, -6.9889e-01],\n",
      "         [ 7.0030e-02, -2.8933e-01, -1.8539e-01]],\n",
      "\n",
      "        [[ 5.6663e-03, -2.5589e-01, -2.0053e-01],\n",
      "         [ 9.8946e-04, -3.7310e-01, -1.3215e+00],\n",
      "         [-1.8603e-02,  2.3993e-01, -4.2145e-01]]], grad_fn=<DivBackward0>)\n",
      "加权自注意力: tensor([[[ 0.4822,  0.0936, -0.8211, -0.0261],\n",
      "         [ 0.6444, -0.1040, -1.0462,  0.3048],\n",
      "         [ 0.4439,  0.1453, -0.7726, -0.1027]],\n",
      "\n",
      "        [[ 0.5080,  0.4865, -0.5447, -0.6990],\n",
      "         [ 0.6557,  0.5236, -0.4017, -0.7416],\n",
      "         [ 0.6158,  0.5346, -0.5460, -0.8147]]], grad_fn=<BmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 4)\n",
    "linear_q = torch.nn.Linear(4, 4)\n",
    "linear_k = torch.nn.Linear(4, 4)\n",
    "linear_v = torch.nn.Linear(4, 4)\n",
    "\n",
    "Q = linear_q(x)\n",
    "K = linear_k(x)\n",
    "V = linear_v(x)\n",
    "\n",
    "raw_weights = torch.bmm(Q, K.transpose(1, 2))\n",
    "print(raw_weights)\n",
    "\n",
    "scale_factor = K.size(-1)**0.5\n",
    "scale_weights = raw_weights / scale_factor\n",
    "print(scale_weights)\n",
    "\n",
    "attn_weights = F.softmax(scale_weights, dim=2)\n",
    "attn_outputs = torch.bmm(attn_weights, V)\n",
    "print(f\"加权自注意力: {attn_outputs}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T09:28:26.268274Z",
     "start_time": "2024-03-26T09:28:26.251174Z"
    }
   },
   "id": "e43bbae6e8d06333",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. 多头自注意力"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e50a15d8817e2a1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.0835,  0.0063, -0.0904],\n",
      "          [ 0.0716, -0.3325,  0.0660],\n",
      "          [-0.1550,  0.3327, -0.1564]],\n",
      "\n",
      "         [[-0.0286, -0.1234, -0.1101],\n",
      "          [ 0.0554, -1.0449, -0.1753],\n",
      "          [-0.0283, -0.0818, -0.0967]]],\n",
      "\n",
      "\n",
      "        [[[-0.0226,  0.0611, -0.0630],\n",
      "          [-0.5410, -0.5744, -0.0994],\n",
      "          [-0.3347, -0.3095, -0.0932]],\n",
      "\n",
      "         [[-0.0369, -0.1251, -0.1534],\n",
      "          [ 0.0999,  0.3243,  0.3613],\n",
      "          [ 0.1801,  0.4295,  0.0500]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[[-0.0591,  0.0045, -0.0639],\n",
      "          [ 0.0506, -0.2351,  0.0466],\n",
      "          [-0.1096,  0.2353, -0.1106]],\n",
      "\n",
      "         [[-0.0202, -0.0873, -0.0779],\n",
      "          [ 0.0392, -0.7388, -0.1239],\n",
      "          [-0.0200, -0.0578, -0.0684]]],\n",
      "\n",
      "\n",
      "        [[[-0.0160,  0.0432, -0.0446],\n",
      "          [-0.3825, -0.4062, -0.0703],\n",
      "          [-0.2367, -0.2189, -0.0659]],\n",
      "\n",
      "         [[-0.0261, -0.0884, -0.1085],\n",
      "          [ 0.0706,  0.2293,  0.2555],\n",
      "          [ 0.1274,  0.3037,  0.0354]]]], grad_fn=<DivBackward0>)\n",
      "多头自注意力: tensor([[[-0.0922, -0.4427, -0.2416, -0.5869],\n",
      "         [-0.0864, -0.4346, -0.2385, -0.5694],\n",
      "         [-0.0903, -0.4401, -0.2387, -0.5908]],\n",
      "\n",
      "        [[-0.1502, -0.6229, -0.5646, -0.2945],\n",
      "         [-0.1591, -0.6298, -0.5736, -0.3060],\n",
      "         [-0.1579, -0.6217, -0.5695, -0.2964]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "x = torch.randn(2, 3, 4)\n",
    "\n",
    "num_heads = 2\n",
    "head_dim = 2\n",
    "\n",
    "assert x.size(-1) == num_heads * head_dim\n",
    "\n",
    "linear_q = torch.nn.Linear(4, 4)\n",
    "linear_k = torch.nn.Linear(4, 4)\n",
    "linear_v = torch.nn.Linear(4, 4)\n",
    "\n",
    "Q = linear_q(x)\n",
    "K = linear_k(x)\n",
    "V = linear_v(x)\n",
    "\n",
    "def split_heads(tensor, num_heads):\n",
    "    batch_size, seq_len, feature_dim = tensor.size()\n",
    "    head_dim = feature_dim // num_heads\n",
    "    output = tensor.view(batch_size, seq_len, num_heads, head_dim).transpose(1, 2)\n",
    "    return output\n",
    "\n",
    "Q = split_heads(Q, num_heads)\n",
    "K = split_heads(K, num_heads)\n",
    "V = split_heads(V, num_heads)\n",
    "\n",
    "raw_weights = torch.matmul(Q, K.transpose(-2, -1))\n",
    "print(raw_weights)\n",
    "\n",
    "scale_factor = K.size(-1)**0.5\n",
    "scale_weights = raw_weights / scale_factor\n",
    "print(scale_weights)\n",
    "\n",
    "attn_weights = F.softmax(scale_weights, dim=-1)\n",
    "attn_outputs = torch.matmul(attn_weights, V)\n",
    "\n",
    "def combine_heads(tensor):\n",
    "    batch_size, num_heads, seq_len, head_dim = tensor.size()\n",
    "    feature_dim = num_heads * head_dim\n",
    "    output = tensor.transpose(1, 2).contiguous().view(batch_size, seq_len, feature_dim)\n",
    "    return output\n",
    "\n",
    "attn_outputs = combine_heads(attn_outputs)\n",
    "\n",
    "linear_out = torch.nn.Linear(4, 4)\n",
    "attn_outputs = linear_out(attn_outputs)\n",
    "\n",
    "print(f\"多头自注意力: {attn_outputs}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T09:45:53.592396Z",
     "start_time": "2024-03-26T09:45:53.565583Z"
    }
   },
   "id": "6102c57502d36b35",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d33f10ce14a22846"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
