{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. 构建语料库"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c586b8833cecda9"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:28:49.904894Z",
     "start_time": "2024-03-14T06:28:49.892864Z"
    }
   },
   "source": [
    "sentences = [\n",
    "    \"Kage is Teacher\", \"Mazong is Boss\", \"Niuzong is Boss\",\n",
    "    \"Xiaobing is Student\", \"Xiaoxue is Student\"\n",
    "]\n",
    "words = \" \".join(sentences).split()\n",
    "word_list = list(set(words))\n",
    "word_to_idx = {w: i for i, w in enumerate(word_list)}\n",
    "idx_to_word = {i: w for i, w in enumerate(word_list)}\n",
    "voc_size = len(word_list)\n",
    "print(f\"词汇表: {word_list}\")\n",
    "print(f\"词汇到索引: {word_to_idx}\")\n",
    "print(f\"索引到词汇: {idx_to_word}\")\n",
    "print(f\"词汇表大小: {voc_size}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. 生成 SkipGram 数据集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5dbdd465921e693"
  },
  {
   "cell_type": "code",
   "source": [
    "def create_skipgram_dataset(sentences, window_size=2):\n",
    "    data = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.split()\n",
    "        for idx, word in enumerate(sentence):\n",
    "            for neighbor in sentence[max(idx - window_size, 0): min(idx + window_size, len(sentence))]:\n",
    "                if neighbor != word:\n",
    "                    data.append((neighbor, word))\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:28:49.974196Z",
     "start_time": "2024-03-14T06:28:49.970361Z"
    }
   },
   "id": "7f5828e779220b8b",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "skipgram_data = create_skipgram_dataset(sentences)\n",
    "print(f\"SkipGram 数据集: {skipgram_data[:3]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:28:50.002146Z",
     "start_time": "2024-03-14T06:28:49.999485Z"
    }
   },
   "id": "e2a76ff6a014ad43",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. 进行 OneHot 编码"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d629222824d5d21"
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "def one_hot_encoding(word, word_to_idx):\n",
    "    tensor = torch.zeros(len(word_to_idx))\n",
    "    tensor[word_to_idx[word]] = 1\n",
    "    return tensor\n",
    "\n",
    "\n",
    "word_sample = \"Teacher\"\n",
    "print(f\"编码前单词: {word_sample}\")\n",
    "print(f\"Onehot 编码: {one_hot_encoding(word_sample, word_to_idx)}\")\n",
    "print(\n",
    "    f\"SkipGram 数据样例: {[(one_hot_encoding(context, word_to_idx), word_to_idx[target]) for context, target in skipgram_data[:3]]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:28:50.122397Z",
     "start_time": "2024-03-14T06:28:50.048323Z"
    }
   },
   "id": "be4f6220c430781f",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. 定义 SkipGram 模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c63ece2179b60944"
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, voc_size, embedding_size):\n",
    "        super().__init__()\n",
    "        self.input_to_hidden = nn.Linear(voc_size, embedding_size, bias=False)\n",
    "        self.hidden_to_output = nn.Linear(embedding_size, voc_size, bias=False)\n",
    "\n",
    "    def forward(self, X):\n",
    "        hidden = self.input_to_hidden(X)\n",
    "        output = self.hidden_to_output(hidden)\n",
    "        return output\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:28:50.126738Z",
     "start_time": "2024-03-14T06:28:50.123818Z"
    }
   },
   "id": "8e48965cdb4edbd",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "embedding_size = 2\n",
    "skipgram_model = SkipGram(voc_size, embedding_size)\n",
    "print(skipgram_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:28:50.136572Z",
     "start_time": "2024-03-14T06:28:50.127908Z"
    }
   },
   "id": "18be95403c049808",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. 训练 SkipGram 模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "492bb2556de4817d"
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs = 1000\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(skipgram_model.parameters(), lr=learning_rate)\n",
    "loss_values = []\n",
    "for epoch in range(epochs):\n",
    "    loss_sum = 0\n",
    "    for context, target in skipgram_data:\n",
    "        X = one_hot_encoding(target, word_to_idx).float().unsqueeze(0)\n",
    "        y_true = torch.tensor([word_to_idx[context]], dtype=torch.long)\n",
    "        y_pred = skipgram_model(X)\n",
    "        loss = criterion(y_pred, y_true)\n",
    "        loss_sum += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch:{epoch + 1}, Loss:{loss_sum / len(skipgram_data)}\")\n",
    "        loss_values.append(loss_sum / len(skipgram_data))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:28:52.440936Z",
     "start_time": "2024-03-14T06:28:50.138126Z"
    }
   },
   "id": "a2179d8445a012f4",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"font.family\"] = [\"Arial Unicode MS\"]\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"Arial Unicode MS\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "plt.plot(range(1, epochs // 100 + 1), loss_values)\n",
    "plt.title(\"训练损失曲线\")\n",
    "plt.xlabel(\"轮次\")\n",
    "plt.ylabel(\"损失\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:28:53.259624Z",
     "start_time": "2024-03-14T06:28:52.442082Z"
    }
   },
   "id": "2078453ea66ded49",
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. 展示词向量"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96aa1f3a2f8a0435"
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"SkimGram Embedding\")\n",
    "for word, idx in word_to_idx.items():\n",
    "    print(f\"{word}: {skipgram_model.input_to_hidden.weight[:, idx].detach().numpy()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:28:53.268492Z",
     "start_time": "2024-03-14T06:28:53.261650Z"
    }
   },
   "id": "36cecf1a673503d8",
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots()\n",
    "for word, idx in word_to_idx.items():\n",
    "    vec = skipgram_model.input_to_hidden.weight[:, idx].detach().numpy()\n",
    "    ax.scatter(vec[0], vec[1])\n",
    "    ax.annotate(word, (vec[0], vec[1]), fontsize=12)\n",
    "plt.title(\"二维词嵌入\")\n",
    "plt.xlabel(\"向量维度 1\")\n",
    "plt.ylabel(\"向量维度 2\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:28:53.415681Z",
     "start_time": "2024-03-14T06:28:53.269616Z"
    }
   },
   "id": "daa09bb35b712e4",
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. 生成 CBOW 数据集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f5f5f49be4a71a3"
  },
  {
   "cell_type": "code",
   "source": [
    "def create_cbow_dataset(sentences, window_size=2):\n",
    "    data = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.split()\n",
    "        for idx, word in enumerate(sentence):\n",
    "            countext_words = sentence[max(idx - window_size, 0): idx] + sentence[idx + 1: min(idx + window_size + 1, len(sentence))]\n",
    "            data.append((word, countext_words))\n",
    "    return data\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:28:53.420227Z",
     "start_time": "2024-03-14T06:28:53.416770Z"
    }
   },
   "id": "971a49f026150457",
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "cbow_data = create_cbow_dataset(sentences)\n",
    "print(f\"Cbow DataSet: {cbow_data[:3]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:28:53.423420Z",
     "start_time": "2024-03-14T06:28:53.421247Z"
    }
   },
   "id": "fc8c859f8a79a6de",
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 8. 构建 CBOW 模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "115f6bbada616c43"
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "class CBOW(nn.Module):\n",
    "    def __init__(self, voc_size, embedding_size):\n",
    "        super().__init__()\n",
    "        self.input_to_hidden = nn.Linear(voc_size, embedding_size, bias=False)\n",
    "        self.hidden_to_output = nn.Linear(embedding_size, voc_size, bias=False)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        embeddings = self.input_to_hidden(X)\n",
    "        hidden_layer  = torch.mean(embeddings, dim=0)\n",
    "        output_layer = self.hidden_to_output(hidden_layer.unsqueeze(0))\n",
    "        return output_layer\n",
    "    \n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:28:53.428007Z",
     "start_time": "2024-03-14T06:28:53.424602Z"
    }
   },
   "id": "fb0ea87848777ba0",
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "embedding_size = 2\n",
    "cbow_model = CBOW(voc_size, embedding_size)\n",
    "print(f\"CBOW model: {cbow_model}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:28:53.433224Z",
     "start_time": "2024-03-14T06:28:53.430692Z"
    }
   },
   "id": "f748c57b7dba0ff9",
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 9. 训练 CBOW 模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8918165be0bef9b6"
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs = 1000\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cbow_model.parameters(), lr=learning_rate)\n",
    "loss_values = []\n",
    "for epoch in range(epochs):\n",
    "    loss_sum = 0\n",
    "    for target, context in cbow_data:\n",
    "        X = torch.stack([one_hot_encoding(w, word_to_idx) for w in context]).float()\n",
    "        y_true = torch.tensor([word_to_idx[target]], dtype=torch.long)\n",
    "        y_pred = cbow_model(X)\n",
    "        loss = criterion(y_pred, y_true)\n",
    "        loss_sum += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch:{epoch + 1}, Loss:{loss_sum / len(skipgram_data)}\")\n",
    "        loss_values.append(loss_sum / len(skipgram_data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:28:55.231418Z",
     "start_time": "2024-03-14T06:28:53.434168Z"
    }
   },
   "id": "68b89bdc54530c3f",
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"font.family\"] = [\"Arial Unicode MS\"]\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"Arial Unicode MS\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "plt.plot(range(1, epochs // 100 + 1), loss_values)\n",
    "plt.title(\"训练损失曲线\")\n",
    "plt.xlabel(\"轮次\")\n",
    "plt.ylabel(\"损失\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:28:55.324351Z",
     "start_time": "2024-03-14T06:28:55.232320Z"
    }
   },
   "id": "481c22274b0408ca",
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots()\n",
    "for word, idx in word_to_idx.items():\n",
    "    vec = skipgram_model.input_to_hidden.weight[:, idx].detach().numpy()\n",
    "    ax.scatter(vec[0], vec[1])\n",
    "    ax.annotate(word, (vec[0], vec[1]), fontsize=12)\n",
    "plt.title(\"二维词嵌入\")\n",
    "plt.xlabel(\"向量维度 1\")\n",
    "plt.ylabel(\"向量维度 2\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:28:55.466003Z",
     "start_time": "2024-03-14T06:28:55.325397Z"
    }
   },
   "id": "9908667810ab2b11",
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    " "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:28:55.468758Z",
     "start_time": "2024-03-14T06:28:55.466966Z"
    }
   },
   "id": "26e50ccc083463a5",
   "execution_count": 18,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
